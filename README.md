# Finger-Detection-Flappy-Professor
CS 470 Final Project

	My Term Project consists of a game using finger recognition. This game is called, “Flappy Professor”. The “Flappy Professor” game consists of one player specifically using their index finger to guide Dr. Terwilliger through a series of intervals of 150 between pipes. The user will only be able to move Dr. Terwilliger up and down to go through these intervals. This game will be infinite along with stages. Each stage will cause the game to go faster which will create a level of difficulty. Once a user touches the pipe then the game is over.
	The methodologies I used was waterfall Model by gathering my requirements for the term project. Next, I would research ideas that met the requirements of the project. I came across facial detection and found it interesting to build within my project. However, I needed to intertwine facial detection within a useful purpose which led to the thought of a game. My research continues as I search for facial detection games and come across different videos that I would be able to use as a source. Once I got an idea of the specific game, I was able to further my research within the facial detection code of the project. I found great websites that explained the code for facial detection, and it was also performed within the video with the game. Finally, I start designing and implementing my code to test if the code that I am following on the video can work properly on my device. I verified that it was able to function perfectly on my device by correcting bugs that I found while watching the video. If there was a bug, then I would search for that error and try to correct it by looking at the difference between my code and the source code from the video. Many bugs were from spelling errors or not importing certain libraries. Another error was the camera, the user in the video used a camera that wasn’t attached to their device which caused them to use a different parameter with in the cv built-in function. Therefore, the maintenance did not consist of any major fixes. After getting the game to function, I started to add a graphical user interface and change from facial detection to finger detection. This process followed the same method of gathering research on these topics and adding it into my code.
	My project is very similar to another project. I did start out tracing code exactly from a video called, “Create Head-Tracking Flappy Bird Game using Computer Vision in Python” ( https://www.youtube.com/watch?v=Tm7Iy6_YW1w). This video allows me to get the basis of the game in code and create the character and move it through the objects. It also how the pipes are placed and explains how the speed is different within the levels of the game. The video does use facial detection, however I changed it to the finger detection by observing how the facial detection was used in the previous code and researching the documentation for hand tracking. The documentations I used for hand tracking were MediaPipe (https://chuoling.github.io/mediapipe/solutions/hands.html) and sectionIO(https://www.section.io/engineering-education/creating-a-hand-tracking-module/). Once everything was working properly, I decided to add a graphical user interface to have the user press a button to play the game and a test button to test their hand tracking. I created my interface by following a game development document on python programming(https://pythonprogramming.net/pygame-start-menu-tutorial/). In all, I used those documentations/sources and create my own adjustments to have it complete my vision of the “Flying Professor” such as importing the character, placing functions within the code, and changing the size of the character to fit within the pipes, changing the confidence within the hand tracking function, and learning or experimenting with the code that I did not write.
	The research and code within the project caused my term project to be a success. The game was accomplished because it allows the user to move the character using their finger without any errors. The goal was to allow the user to play a successful game without any errors by using their finger and I met that goal. I did face some obstacles where the user must be up close to play the game. I also faced an obstacle of having the character lose track of the finger more on the left hand than the right hand. However, this project taught me a lot about facial detection, finger detection, the process of how a game is developed through code. If I had more time to work on this project, then I would have it on a website or app. I would also test it with other detections such as nose, different fingers, and I would add specifics for the user to choose from such as characters or which finger to use. 
References
info:
https://ai.googleblog.com/2019/08/on-device-real-time-hand-tracking-with.html
game
https://www.section.io/engineering-education/creating-a-hand-tracking-module/
https://www.youtube.com/watch?v=Tm7Iy6_YW1w
https://chuoling.github.io/mediapipe/solutions/hands.html
GUI
intro: https://www.youtube.com/watch?v=jh_m-Eytq0Q&list=PLQVvvaa0QuDdLkP8MrOXLe_rKuf6r80KO&index=11
intro: https://pythonprogramming.net/pygame-start-menu-tutorial/
counter:https://stackoverflow.com/questions/30720665/countdown-timer-in-pygame
test:
https://techtutorialsx.com/2021/04/24/python-mediapipe-finger-roi/#The_code
